{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier detection using autoencodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano import tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(object):\n",
    "    def __init__(self, X, hidden_size, activation_function,\n",
    "                 output_function):\n",
    "        #X is the data, an m x n numpy matrix\n",
    "        #where rows correspond to datapoints\n",
    "        #and columns correspond to features.\n",
    "        assert type(X) is np.ndarray\n",
    "        assert len(X.shape)==2\n",
    "        self.X=X\n",
    "        self.X=th.shared(name='X', value=np.asarray(self.X, \n",
    "                         dtype=th.config.floatX),borrow=True)\n",
    "        #The config.floatX and borrow=True stuff is to get this to run\n",
    "        #fast on the gpu. I recommend just doing this without thinking about\n",
    "        #it until you understand the code as a whole, then learning more\n",
    "        #about gpus and theano.\n",
    "        self.n = X.shape[1]\n",
    "        self.m = X.shape[0]\n",
    "        #Hidden_size is the number of neurons in the hidden layer, an int.\n",
    "        assert type(hidden_size) is int\n",
    "        assert hidden_size > 0\n",
    "        self.hidden_size=hidden_size\n",
    "        initial_W = np.asarray(rng.uniform(\n",
    "                 low=-4 * np.sqrt(6. / (self.hidden_size + self.n)),\n",
    "                 high=4 * np.sqrt(6. / (self.hidden_size + self.n)),\n",
    "                 size=(self.n, self.hidden_size)), dtype=th.config.floatX)\n",
    "        self.W = th.shared(value=initial_W, name='W', borrow=True)\n",
    "        self.b1 = th.shared(name='b1', value=np.zeros(shape=(self.hidden_size,),\n",
    "                            dtype=th.config.floatX),borrow=True)\n",
    "        self.b2 = th.shared(name='b2', value=np.zeros(shape=(self.n,),\n",
    "                            dtype=th.config.floatX),borrow=True)\n",
    "        self.activation_function=activation_function\n",
    "        self.output_function=output_function\n",
    "                     \n",
    "    def train(self, n_epochs=100, mini_batch_size=1, learning_rate=0.1):\n",
    "        index = T.lscalar()\n",
    "        x=T.matrix('x')\n",
    "        params = [self.W, self.b1, self.b2]\n",
    "        hidden = self.activation_function(T.dot(x, self.W)+self.b1)\n",
    "        output = T.dot(hidden,T.transpose(self.W))+self.b2\n",
    "        output = self.output_function(output)\n",
    "         \n",
    "        #Use cross-entropy loss.\n",
    "        L = -T.sum(x*T.log(output) + (1-x)*T.log(1-output), axis=1)\n",
    "        cost=L.mean()       \n",
    "        updates=[]\n",
    "         \n",
    "        #Return gradient with respect to W, b1, b2.\n",
    "        gparams = T.grad(cost,params)\n",
    "         \n",
    "        #Create a list of 2 tuples for updates.\n",
    "        for param, gparam in zip(params, gparams):\n",
    "            updates.append((param, param-learning_rate*gparam))\n",
    "         \n",
    "        #Train given a mini-batch of the data.\n",
    "        train = th.function(inputs=[index], outputs=[cost], updates=updates,\n",
    "                            givens={x:self.X[index:index+mini_batch_size,:]})\n",
    "                             \n",
    " \n",
    "        import time\n",
    "        start_time = time.clock()\n",
    "        for epoch in range(n_epochs):\n",
    "            print(\"Epoch:\",epoch)\n",
    "            for row in range(0,self.m, mini_batch_size):\n",
    "                train(row)\n",
    "        end_time = time.clock()\n",
    "        print(\"Average time per epoch=\", (end_time-start_time)/n_epochs)\n",
    "                    \n",
    "    def get_hidden(self,data):\n",
    "        x=T.dmatrix('x')\n",
    "        hidden = self.activation_function(T.dot(x,self.W)+self.b1)\n",
    "        transformed_data = th.function(inputs=[x], outputs=[hidden])\n",
    "        return transformed_data(data)\n",
    "     \n",
    "    def get_weights(self):\n",
    "        return [self.W.get_value(), self.b1.get_value(), self.b2.get_value()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numpy import random as rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=\"mnist.pkl/mnist.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), array([5, 0, 4, ..., 8, 4, 8], dtype=int64)), (array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), array([3, 8, 6, ..., 5, 6, 8], dtype=int64)), (array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), array([7, 2, 1, ..., 4, 5, 6], dtype=int64)))\n"
     ]
    }
   ],
   "source": [
    "with open(path, 'rb') as f:\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    p = u.load()\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_first_k_numbers(X,k):\n",
    "    from matplotlib import mpl,pyplot\n",
    "    m=X.shape[0]\n",
    "    k=min(m,k)\n",
    "    j = int(round(k / 10.0))\n",
    "     \n",
    "    fig, ax = pyplot.subplots(j,10)\n",
    "    \n",
    "    for i in range(k):\n",
    " \n",
    "        w=X[i,:]\n",
    " \n",
    "         \n",
    "        w=w.reshape(28,28)\n",
    "        ax[i/10, i%10].imshow(w,cmap=pyplot.cm.gist_yarg,\n",
    "                      interpolation='nearest', aspect='equal')\n",
    "        ax[i/10, i%10].axis('off')\n",
    " \n",
    "     \n",
    "    pyplot.tick_params(\\\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelbottom='off')\n",
    "    pyplot.tick_params(\\\n",
    "        axis='y',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        left='off', \n",
    "        right='off',    # ticks along the top edge are off\n",
    "        labelleft='off')\n",
    "     \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def m_test(data):\n",
    "    X=data[0][0]\n",
    "    activation_function = T.nnet.sigmoid\n",
    "    output_function=activation_function\n",
    "    A = AutoEncoder(X, 500, activation_function, output_function)\n",
    "    A.train(20,20)\n",
    "    W=np.transpose(A.get_weights()[0])\n",
    "    plot_first_k_numbers(W, 100, False)\n",
    "    plot_first_k_numbers(W,100, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0e6b51a4e269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-178b6571d364>\u001b[0m in \u001b[0;36mm_test\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutput_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplot_first_k_numbers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-d74842035666>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_epochs, mini_batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Average time per epoch=\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\Users\\S37283\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m_test(p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
